{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da684289",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANN) for Branch Prediction\n",
    "\n",
    "This notebook implements a standard feedforward Artificial Neural Network to predict CPU branch behavior (Taken/Not Taken).\n",
    "\n",
    "## Network Architecture:\n",
    "- **Input Layer**: 64 neurons (32 PC bits + 32 Branch History bits)\n",
    "- **Hidden Layer**: 16 neurons with ReLU activation\n",
    "- **Output Layer**: 2 neurons (Taken / Not Taken) with Softmax\n",
    "\n",
    "## Approach:\n",
    "- Standard feedforward neural network using PyTorch\n",
    "- Binary classification using Cross Entropy Loss\n",
    "- Dropout for regularization\n",
    "- Batch Normalization for stable training\n",
    "- **Same architecture as SNN for fair comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1f26c",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae48727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /localhome/kanishka/miniconda/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: pandas in /localhome/kanishka/miniconda/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /localhome/kanishka/miniconda/lib/python3.13/site-packages (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /localhome/kanishka/miniconda/lib/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /localhome/kanishka/miniconda/lib/python3.13/site-packages (3.10.8)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tqdm in /localhome/kanishka/miniconda/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /localhome/kanishka/miniconda/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch pandas numpy scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f59b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "‚úì Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "# Check if GPU 1 exists, otherwise fall back to standard logic\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.device(\"cuda:1\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU 1 not found. Falling back to default.\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e9f7e",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95b566c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: branch_data_processed.csv\n",
      "\n",
      "‚úì Dataset loaded successfully!\n",
      "Shape: (350783, 65)\n",
      "Columns: 65\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_0</th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>PC_8</th>\n",
       "      <th>PC_9</th>\n",
       "      <th>...</th>\n",
       "      <th>BH_23</th>\n",
       "      <th>BH_24</th>\n",
       "      <th>BH_25</th>\n",
       "      <th>BH_26</th>\n",
       "      <th>BH_27</th>\n",
       "      <th>BH_28</th>\n",
       "      <th>BH_29</th>\n",
       "      <th>BH_30</th>\n",
       "      <th>BH_31</th>\n",
       "      <th>Taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PC_0  PC_1  PC_2  PC_3  PC_4  PC_5  PC_6  PC_7  PC_8  PC_9  ...  BH_23  \\\n",
       "0     0     0     0     0     0     1     0     1     1     1  ...      0   \n",
       "1     0     0     0     0     0     1     0     1     1     1  ...      0   \n",
       "2     0     0     0     0     0     1     0     1     1     1  ...      0   \n",
       "3     0     0     0     0     0     1     0     1     1     1  ...      0   \n",
       "4     0     0     0     0     0     1     0     1     1     1  ...      0   \n",
       "\n",
       "   BH_24  BH_25  BH_26  BH_27  BH_28  BH_29  BH_30  BH_31  Taken  \n",
       "0      0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0      1  \n",
       "2      0      0      0      0      0      0      0      0      1  \n",
       "3      0      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0      1  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the processed branch prediction dataset\n",
    "data_file = 'branch_data_processed.csv'\n",
    "\n",
    "print(f\"Loading dataset: {data_file}\")\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "print(f\"\\n‚úì Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f930c1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (350783, 64)\n",
      "Target shape: (350783,)\n",
      "\n",
      "Target distribution:\n",
      "  Not Taken (0): 153,486 (43.76%)\n",
      "  Taken (1): 197,297 (56.24%)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.iloc[:, :64].values  # 64 input features (32 PC + 32 BH)\n",
    "y = df.iloc[:, -1].values   # Target (0 or 1)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Not Taken (0): {np.sum(y == 0):,} ({np.mean(y == 0)*100:.2f}%)\")\n",
    "print(f\"  Taken (1): {np.sum(y == 1):,} ({np.mean(y == 1)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e679d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1962040761.py, line 21)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"\\nTensor shapes:\")print(f\"  X_train: {X_train_tensor.shape}\")\u001b[39m\n                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets SEQUENTIALLY (no shuffling)\n",
    "# This preserves temporal order - crucial for branch prediction patterns!\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train = X[:split_idx]\n",
    "y_train = y[:split_idx]\n",
    "X_test = X[split_idx:]\n",
    "y_test = y[split_idx:]\n",
    "\n",
    "print(f\"‚úì Sequential split (maintains execution order)\")\n",
    "print(f\"Training set size: {len(X_train):,} (first 80%)\")\n",
    "print(f\"Test set size: {len(X_test):,} (last 20%)\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "print(f\"  y_train: {y_train_tensor.shape}\")\n",
    "\n",
    "print(f\"\\nTensor shapes:\")\n",
    "print(f\"  X_train: {X_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "# shuffle=False to maintain sequential order!\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f720b3",
   "metadata": {},
   "source": [
    "## 3. Define ANN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchPredictorANN(nn.Module):\n",
    "    \"\"\"\n",
    "    Artificial Neural Network for Branch Prediction\n",
    "    \n",
    "    Architecture:\n",
    "    - Input: 64 neurons\n",
    "    - Hidden Layer: 16 neurons + BatchNorm + ReLU + Dropout\n",
    "    - Output: 2 neurons (Taken / Not Taken)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=64, hidden_size=16, output_size=2, dropout=0.3):\n",
    "        super(BranchPredictorANN, self).__init__()\n",
    "        \n",
    "        # Hidden layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = BranchPredictorANN(\n",
    "    input_size=64,\n",
    "    hidden_size=16,\n",
    "    output_size=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(\"Artificial Neural Network Architecture:\")\n",
    "print(\"=\"*50)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe872f02",
   "metadata": {},
   "source": [
    "## 4. Define Loss, Optimizer, and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca90c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "print(\"Loss function: Cross Entropy Loss\")\n",
    "print(\"Optimizer: Adam (lr=0.001, weight_decay=1e-5)\")\n",
    "print(\"Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, targets in train_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate the model on test data.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy, all_predictions, all_targets, all_probabilities\n",
    "\n",
    "print(\"‚úì Training and evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722f5a0",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ed7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 5\n",
    "\n",
    "# Lists to store training history\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"TRAINING ARTIFICIAL NEURAL NETWORK\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nEpochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_acc, _, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        # Store history\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1:2d}/{num_epochs}] | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    print(\"-\"*70)\n",
    "    print(f\"\\n‚úì Training complete!\")\n",
    "    print(f\"Best Test Accuracy: {max(test_accuracies):.2f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during training: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a74b30",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(range(1, num_epochs+1), train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(range(1, num_epochs+1), test_losses, 'r-', label='Test Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(range(1, num_epochs+1), train_accuracies, 'b-', label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(range(1, num_epochs+1), test_accuracies, 'r-', label='Test Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Test Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ann_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training history saved to 'ann_training_history.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884e5b1",
   "metadata": {},
   "source": [
    "## 7. Final Evaluation and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "print(\"Running final inference on test set...\\n\")\n",
    "\n",
    "test_loss, test_acc, predictions, targets, probabilities = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"INFERENCE RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüéØ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"üìâ Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nüìä Classification Report:\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(targets, predictions, target_names=['Not Taken', 'Taken']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beed96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(targets, predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not Taken', 'Taken'],\n",
    "            yticklabels=['Not Taken', 'Taken'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - ANN Branch Prediction', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ann_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Confusion matrix saved to 'ann_confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65513f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "probabilities_np = np.array(probabilities)\n",
    "fpr, tpr, thresholds = roc_curve(targets, probabilities_np[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ann_roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì ROC curve saved to 'ann_roc_curve.png'\")\n",
    "print(f\"   AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction confidence distribution\n",
    "probabilities_np = np.array(probabilities)\n",
    "max_probs = np.max(probabilities_np, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall confidence distribution\n",
    "axes[0].hist(max_probs, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Prediction Confidence', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Overall Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Confidence by correctness\n",
    "correct_mask = np.array(predictions) == np.array(targets)\n",
    "correct_probs = max_probs[correct_mask]\n",
    "incorrect_probs = max_probs[~correct_mask]\n",
    "\n",
    "axes[1].hist(correct_probs, bins=30, alpha=0.6, label='Correct', color='green', edgecolor='black')\n",
    "axes[1].hist(incorrect_probs, bins=30, alpha=0.6, label='Incorrect', color='red', edgecolor='black')\n",
    "axes[1].set_xlabel('Prediction Confidence', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Confidence by Prediction Correctness', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ann_confidence_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Confidence distribution saved to 'ann_confidence_distribution.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f910b",
   "metadata": {},
   "source": [
    "## 8. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = 'ann_branch_predictor.pth'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'test_losses': test_losses,\n",
    "    'test_accuracies': test_accuracies,\n",
    "    'num_epochs': num_epochs,\n",
    "    'final_accuracy': test_acc,\n",
    "    'auc_score': roc_auc\n",
    "}, model_path)\n",
    "\n",
    "print(f\"‚úì Model saved to '{model_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d0aab",
   "metadata": {},
   "source": [
    "## 9. Compare with SNN (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473896ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison summary\n",
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"ANN vs SNN COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Architecture (Both Models):\")\n",
    "print(f\"   Input Layer: 64 neurons\")\n",
    "print(f\"   Hidden Layer: 16 neurons\")\n",
    "print(f\"   Output Layer: 2 neurons\")\n",
    "\n",
    "print(\"\\nüìä ANN Model:\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"   Training Time: ~{num_epochs} epochs\")\n",
    "\n",
    "print(\"\\nüí° Advantages of ANN:\")\n",
    "print(\"   ‚úì Faster training and inference\")\n",
    "print(\"   ‚úì More mature optimization techniques\")\n",
    "print(\"   ‚úì Standard backpropagation\")\n",
    "print(\"   ‚úì Easier to debug and tune\")\n",
    "print(\"   ‚úì Better regularization options\")\n",
    "\n",
    "print(\"\\n‚ö° Advantages of SNN:\")\n",
    "print(\"   ‚úì Biologically plausible\")\n",
    "print(\"   ‚úì Event-driven computation\")\n",
    "print(\"   ‚úì Potential for energy efficiency\")\n",
    "print(\"   ‚úì Temporal dynamics modeling\")\n",
    "print(\"   ‚úì Suitable for neuromorphic hardware\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb97cd",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*15 + \"ARTIFICIAL NEURAL NETWORK - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Network Architecture:\")\n",
    "print(f\"   Input Layer: 64 neurons (32 PC + 32 Branch History bits)\")\n",
    "print(f\"   Hidden Layer: 16 neurons (BatchNorm + ReLU + Dropout)\")\n",
    "print(f\"   Output Layer: 2 neurons (Softmax)\")\n",
    "print(f\"   Total Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"   Epochs: {num_epochs}\")\n",
    "print(f\"   Batch Size: {batch_size}\")\n",
    "print(f\"   Learning Rate: 0.001 (adaptive)\")\n",
    "print(f\"   Optimizer: Adam with weight decay\")\n",
    "print(f\"   Dropout: 0.3\")\n",
    "\n",
    "print(f\"\\nüìà Dataset:\")\n",
    "print(f\"   Training samples: {len(X_train):,}\")\n",
    "print(f\"   Test samples: {len(X_test):,}\")\n",
    "\n",
    "print(f\"\\nüéØ Final Results:\")\n",
    "print(f\"   Training Accuracy: {train_accuracies[-1]:.2f}%\")\n",
    "print(f\"   Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   Best Test Accuracy: {max(test_accuracies):.2f}%\")\n",
    "print(f\"   AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Files:\")\n",
    "print(f\"   Model: ann_branch_predictor.pth\")\n",
    "print(f\"   Training History: ann_training_history.png\")\n",
    "print(f\"   Confusion Matrix: ann_confusion_matrix.png\")\n",
    "print(f\"   ROC Curve: ann_roc_curve.png\")\n",
    "print(f\"   Confidence Distribution: ann_confidence_distribution.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì Implementation complete! ANN model trained successfully.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be7b31",
   "metadata": {},
   "source": [
    "## 10. Feature Ablation Study - PC Only Model\n",
    "\n",
    "Train an ANN using only Program Counter (PC) bits to evaluate their individual contribution to prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare PC-only dataset (first 32 columns)\n",
    "X_train_pc = X_train[:, :32]  # PC bits only\n",
    "X_test_pc = X_test[:, :32]\n",
    "\n",
    "print(\"PC-Only Dataset:\")\n",
    "print(f\"  Training shape: {X_train_pc.shape}\")\n",
    "print(f\"  Test shape: {X_test_pc.shape}\")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_pc_tensor = torch.FloatTensor(X_train_pc)\n",
    "X_test_pc_tensor = torch.FloatTensor(X_test_pc)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset_pc = TensorDataset(X_train_pc_tensor, y_train_tensor)\n",
    "test_dataset_pc = TensorDataset(X_test_pc_tensor, y_test_tensor)\n",
    "\n",
    "train_loader_pc = DataLoader(train_dataset_pc, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader_pc = DataLoader(test_dataset_pc, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "print(f\"  Training batches: {len(train_loader_pc)}\")\n",
    "print(f\"  Test batches: {len(test_loader_pc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512302d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PC-only ANN model (32 inputs)\n",
    "model_pc = BranchPredictorANN(\n",
    "    input_size=32,  # Only PC bits\n",
    "    hidden_size=16,\n",
    "    output_size=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nüìä PC-Only ANN Architecture:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"   Input: 32 neurons (PC bits only)\")\n",
    "print(f\"   Hidden: 16 neurons (BatchNorm + ReLU + Dropout)\")\n",
    "print(f\"   Output: 2 neurons\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model_pc.parameters()):,}\")\n",
    "\n",
    "# Setup optimizer and scheduler for PC model\n",
    "optimizer_pc = torch.optim.Adam(model_pc.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler_pc = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_pc, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PC-only model\n",
    "train_losses_pc = []\n",
    "train_accuracies_pc = []\n",
    "test_losses_pc = []\n",
    "test_accuracies_pc = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*18 + \"TRAINING PC-ONLY ANN MODEL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input features: PC bits only (32 neurons)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model_pc, train_loader_pc, optimizer_pc, criterion, device)\n",
    "        test_loss, test_acc, _, _, _ = evaluate(model_pc, test_loader_pc, criterion, device)\n",
    "        scheduler_pc.step(test_loss)\n",
    "        \n",
    "        train_losses_pc.append(train_loss)\n",
    "        train_accuracies_pc.append(train_acc)\n",
    "        test_losses_pc.append(test_loss)\n",
    "        test_accuracies_pc.append(test_acc)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f\"Epoch [{epoch+1:2d}/{num_epochs}] | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(f\"‚úì PC-Only Model Training Complete!\")\n",
    "    print(f\"   Best Test Accuracy: {max(test_accuracies_pc):.2f}%\")\n",
    "    print(f\"   Final Test Accuracy: {test_accuracies_pc[-1]:.2f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d04539",
   "metadata": {},
   "source": [
    "## 11. Feature Ablation Study - Branch History Only Model\n",
    "\n",
    "Train an ANN using only Branch History bits to evaluate their individual contribution to prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Branch History-only dataset (columns 32-63)\n",
    "X_train_bh = X_train[:, 32:64]  # Branch History bits only\n",
    "X_test_bh = X_test[:, 32:64]\n",
    "\n",
    "print(\"Branch History-Only Dataset:\")\n",
    "print(f\"  Training shape: {X_train_bh.shape}\")\n",
    "print(f\"  Test shape: {X_test_bh.shape}\")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_bh_tensor = torch.FloatTensor(X_train_bh)\n",
    "X_test_bh_tensor = torch.FloatTensor(X_test_bh)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset_bh = TensorDataset(X_train_bh_tensor, y_train_tensor)\n",
    "test_dataset_bh = TensorDataset(X_test_bh_tensor, y_test_tensor)\n",
    "\n",
    "train_loader_bh = DataLoader(train_dataset_bh, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader_bh = DataLoader(test_dataset_bh, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "print(f\"  Training batches: {len(train_loader_bh)}\")\n",
    "print(f\"  Test batches: {len(test_loader_bh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Branch History-only ANN model (32 inputs)\n",
    "model_bh = BranchPredictorANN(\n",
    "    input_size=32,  # Only Branch History bits\n",
    "    hidden_size=16,\n",
    "    output_size=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nüìä Branch History-Only ANN Architecture:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"   Input: 32 neurons (Branch History bits only)\")\n",
    "print(f\"   Hidden: 16 neurons (BatchNorm + ReLU + Dropout)\")\n",
    "print(f\"   Output: 2 neurons\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model_bh.parameters()):,}\")\n",
    "\n",
    "# Setup optimizer and scheduler for BH model\n",
    "optimizer_bh = torch.optim.Adam(model_bh.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler_bh = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_bh, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ae337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Branch History-only model\n",
    "train_losses_bh = []\n",
    "train_accuracies_bh = []\n",
    "test_losses_bh = []\n",
    "test_accuracies_bh = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*13 + \"TRAINING BRANCH HISTORY-ONLY ANN MODEL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input features: Branch History bits only (32 neurons)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model_bh, train_loader_bh, optimizer_bh, criterion, device)\n",
    "        test_loss, test_acc, _, _, _ = evaluate(model_bh, test_loader_bh, criterion, device)\n",
    "        scheduler_bh.step(test_loss)\n",
    "        \n",
    "        train_losses_bh.append(train_loss)\n",
    "        train_accuracies_bh.append(train_acc)\n",
    "        test_losses_bh.append(test_loss)\n",
    "        test_accuracies_bh.append(test_acc)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f\"Epoch [{epoch+1:2d}/{num_epochs}] | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(f\"‚úì Branch History-Only Model Training Complete!\")\n",
    "    print(f\"   Best Test Accuracy: {max(test_accuracies_bh):.2f}%\")\n",
    "    print(f\"   Final Test Accuracy: {test_accuracies_bh[-1]:.2f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe674a",
   "metadata": {},
   "source": [
    "## 12. Compare All Three Models\n",
    "\n",
    "Compare the performance of Full model (PC + BH), PC-only model, and Branch History-only model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fafcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation for all models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*15 + \"FEATURE ABLATION STUDY - RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get final test accuracies\n",
    "_, acc_full, _, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "_, acc_pc, _, _, _ = evaluate(model_pc, test_loader_pc, criterion, device)\n",
    "_, acc_bh, _, _, _ = evaluate(model_bh, test_loader_bh, criterion, device)\n",
    "\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Model':<30} {'Input Features':<20} {'Test Accuracy':<15}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Full Model (PC + BH)':<30} {'64 neurons':<20} {acc_full:>6.2f}%\")\n",
    "print(f\"{'PC-Only Model':<30} {'32 neurons':<20} {acc_pc:>6.2f}%\")\n",
    "print(f\"{'Branch History-Only Model':<30} {'32 neurons':<20} {acc_bh:>6.2f}%\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\nüîç Feature Importance Analysis:\")\n",
    "print(f\"   Full Model Accuracy: {acc_full:.2f}%\")\n",
    "print(f\"   PC Contribution: {acc_pc:.2f}%\")\n",
    "print(f\"   Branch History Contribution: {acc_bh:.2f}%\")\n",
    "print(f\"   Synergy (Full - Max(PC, BH)): {acc_full - max(acc_pc, acc_bh):.2f}%\")\n",
    "\n",
    "if acc_pc > acc_bh:\n",
    "    print(f\"\\nüí° PC bits are more predictive ({acc_pc:.2f}% vs {acc_bh:.2f}%)\")\n",
    "elif acc_bh > acc_pc:\n",
    "    print(f\"\\nüí° Branch History bits are more predictive ({acc_bh:.2f}% vs {acc_pc:.2f}%)\")\n",
    "else:\n",
    "    print(f\"\\nüí° PC and Branch History have equal predictive power\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "models = ['Full Model\\n(PC + BH)', 'PC Only', 'Branch History\\nOnly']\n",
    "accuracies = [acc_full, acc_pc, acc_bh]\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
    "\n",
    "bars = axes[0].bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Feature Ablation Study - Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim([0, 100])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.2f}%',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Training history comparison\n",
    "axes[1].plot(range(1, num_epochs+1), test_accuracies, 'o-', label='Full Model (PC + BH)', \n",
    "            linewidth=2, markersize=4, color=colors[0])\n",
    "axes[1].plot(range(1, num_epochs+1), test_accuracies_pc, 's-', label='PC Only', \n",
    "            linewidth=2, markersize=4, color=colors[1])\n",
    "axes[1].plot(range(1, num_epochs+1), test_accuracies_bh, '^-', label='Branch History Only', \n",
    "            linewidth=2, markersize=4, color=colors[2])\n",
    "axes[1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Training Progress Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10, loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ann_feature_ablation_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Feature ablation comparison saved to 'ann_feature_ablation_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b71198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models\n",
    "torch.save({\n",
    "    'model_state_dict': model_pc.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_pc.state_dict(),\n",
    "    'test_accuracies': test_accuracies_pc,\n",
    "    'final_accuracy': acc_pc\n",
    "}, 'ann_pc_only.pth')\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_bh.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_bh.state_dict(),\n",
    "    'test_accuracies': test_accuracies_bh,\n",
    "    'final_accuracy': acc_bh\n",
    "}, 'ann_bh_only.pth')\n",
    "\n",
    "print(\"‚úì PC-Only model saved to 'ann_pc_only.pth'\")\n",
    "print(\"‚úì Branch History-Only model saved to 'ann_bh_only.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
